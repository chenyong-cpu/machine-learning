# 研究生工作周报[第四周]

## 学习目标

1. 机器学习实战(监督学习部分)
   1. 分类
      1. k-近邻算法
      2. 决策树
      3. 朴素贝叶斯
      4. Logistic回归
      5. 支持向量机
      6. AdaBoost元算法
   2. 回归
      1. 线性回归
      2. 局部加权回归
      3. 树回归

## 学习内容

1. 机器学习实战监督学习部分

## 学习时间

* 5.29~6.04

## 学习产出

1. [Python代码](./code/)
2. github记录

## 算法演练

1. k-近邻算法
   1. 工作原理:存在一个训练样本集合,计算测试样本与训练样本距离最近的前k(k通常不大于20)个值,取其中出现次数最多的为测试样本的分类
   2. 算法实现

      ```python
      def classify0(inX, dataSet, labels, k):
         dataSetSize = dataSet.shape[0]
         # 距离计算
         # tile重复某个数组,并且特征值之间相减
         diffMat = tile(inX, (dataSetSize, 1)) - dataSet
         sqDiffMat = diffMat ** 2
         sqDistances = sqDiffMat.sum(axis=1)
         distances = sqDistances ** 0.5
         # 选择距离最小的k个点
         sortedDistdices = distances.argsort()
         classCount = {}
         for i in range(k):
            voteIlabel = labels[sortedDistdices[i]]
            classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1
         sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)
         return sortedClassCount[0][0]
      ```

   3. 总结
      1. k-近邻算法是分类算法中最简单有效的算法
      2. 不过k-近邻算法需要保持所以数据集,不仅需要占据大量的储存空间,计算也较为耗时

2. 决策树
   1. 工作原理
      1. 计算香农熵:$H =-\Sigma _{i=1} ^n p(x_i)\log_x p(x_i)$
      2. 选择最好的信息增溢
      3. 构建决策树
