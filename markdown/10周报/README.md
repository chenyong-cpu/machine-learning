# 研究生（周报第十三周）

## 学习目标

### U-Net模型详解

U-Net最早是在医学图像领域提出用于医学图像的语义分割的模型，它的网络结构如下图所示。

![avator](./resource/Unet.png)

输入的是572x572维的灰度图，经过5层卷积，每层都是用3x3的卷积核，且不加padding，因此每次卷积后会是用2x2的Maxpooling。

**第五层卷积结束后图像维度是28x28，通道数是1024。**

对其做2x2的上采样卷积，得到图像维度是56x56，通道数是512的特征图。再将第四层卷积的输出通过crop操作将64x64变为56x56后，于第五次上采样后的特征图进行concat操作，得到通道数为1024大小为56x56的特征图。再对其进行同样的卷积、上采样并与再上一层的输出crop后进行concat，总共进行4次上采样。

**最后一层采用1×1的卷积，输出通道为2，大小为388×388的医学图像语义分割图。**

### 蒙特卡罗方法

随机计算可以粗略地分为两类：Las Vegas算法和蒙特卡罗算法。Las Vegas算法总是精确地返回一个正确答案（或者算法失败），这类算法通常需要占用随机量地计算资源。蒙特卡洛方法返回地答案具有随机大小地错误。

1. 采样和蒙特卡罗方法
    
    当我们需要以较小地代价近似许多项地和或者某个积分时，采样是一种很灵活地选择，有时候可以用于加速一些很费时却易于处理地求和估计。

2. 蒙特卡罗采样的基础

    当无法精确计算和或积分时，通常可以使用蒙特卡罗采样来近似它。这种想法把和或者积分视作某分布下的期望，然后通过估计对应地平均值来近似这个期望。令
    $$s=\sum_{x}p(x)f(x)=E_{p}[f(x)]$$
    为我们所需要估计地和或者积分，写成期望地形式，$p$是一个关于随机变量$x$地概率分布或者概率密度函数。
    可以从$p$中抽取$n$个样本$x^{(1)},\cdots, x^{(n)}$来近似$s$并得到一个经验平均值
    $$\hat{s}_{n}=\frac{1}{n}\sum_{i=1}^{n}f(x^{(i)})$$
    以上结论依赖于我们可以从基准分布$p(x)$中轻易地采样，但是这个假设并不是一直成立的。当我们无法从$p$中采样时，一个备选方案时用重要采样，另一种更加通用的方式时构建一个收敛到目标分布的估计序列。

3. 重要采样

	在蒙特卡罗方法中，对积分（或者和）分解，确定积分中哪一部分作为概率分布$p(x)$以及哪一部分作为被积的函数$f(x)$是很关键的一步。$p(x)f(x)$不存在唯一的分解，因为它总是可以被写成
	$$p(x)f(x)=q(x)\frac{p(x)f(x)}{q(x)}$$
	可以发现任意蒙特卡罗估计可以被转化为一个重要采样的估计
	$$\hat{s}_{q}=\frac{1}{n}\sum_{i=1,x^{(i)}~q}^{n}\frac{p(x^{(i)}f(x^{(i)}))}{q(x^{(i)})}$$
	重要采样的方差可能对$q$的选择非常敏感，方差想要取到最小值，$q$需要满足$q^{*}(x)=\frac{p(x)|f(x)|}{Z}$，这里$Z$表示归一化常数。对于重要采样来说任何的$q$分布都是可行的，$q^{*}$指的是最优的$q$分布。
	
	另一种方法是采用**有偏重要采样**，这种方法有一个优势，即不需要归一化的$p$或$q$分布，在处理离散变量时，有偏重要采样估计可以表示为
	$$\hat{s}_{BIS}=\frac{\sum_{i=1}^{n}\frac{\tilde{p}(x^{(i)})}{\tilde{q}(x^{(i)})}f(x^{(i)})}{\sum_{i=1}^{n}\frac{\tilde{p}(x^{(i)})}{\tilde{q}(x^{(i)})}}$$

4. 马尔可夫链蒙特卡罗方法（Markov Chain Monte Carlo, MCMC)
	
	许多实例中使用蒙特卡罗方法往往不存在一个简单的方法可以直接从目标分布$p_{model}(x)$中精确采样或者一个好的重要采样分布$q(x)$，其实是当分布$p_{model}(x)$为无向模型时，因此引入一种称为马尔可夫链（Markov Chain）的数学工具。
	
	基于能量的模型采样苦难，首先考虑一个包含两个变量的$EBM$的例子，记$p(a,b)$为其分布。为了采$a$，我们必须先从$p(a|b)$中采样；为了采$b$，我们又必须从$p(b|a)$中采样。这似乎成了棘手的先有鸡还是先有蛋的问题。有向模型避免了这一问题因为它的图是有向无环的。
	
	在$EBM$中，我们通过使用马尔可夫链来采样，从而避免了现有鸡还是现有蛋的问题。马尔可夫链的核心思想是从某个可取任意值的状态$x$出发，随机时间的推移，我们随机地反复更新状态$x$。最终$x$成为了一个从$p(x)$中抽出的比较一般的样本。

	$MCMC$方法是使用马尔可夫链的蒙特卡罗积分，其基本思想是：构造一条$Markov$链使其平稳分布为待估参数的后验分布$\pi (x)$，通过这条马尔可夫链产生后验分布的样本，并基于马尔可夫链达到平稳分布时的样本（有效样本）进行蒙特卡罗积分。设$n$为产生的总样本数，$m$为$Markov$链达到平稳时的样本数则$MCMC$方法的基本思路可以概况为：
	
	* 构造$Markov$链。构造一条$Markov$链，给定马尔可夫状态转移矩阵$Q$，使其收敛到平稳分布$\pi (x)$；

	* 产生样本：从初始状态$x_0\sim p_0$出发，利用从条件概率分布$Q(x|x_t)$生成样本，并通过条件判断是否转移，通过$m$次更新达到平稳，此后生成的即为$\pi (x)$的样本，我们记为$x^{(1)},\cdots,x^{(n)}$；

	* 蒙特卡罗积分。任一函数$f(x)$的期望估计为：$\frac{1}{n}\sum_{i=1}^{n}f(x^{(i)})$

5. Gibbs采样

	**Gibbs采样**是一种概念简单而有效的方法，它构造一个从$p_{model}(x)$中采样的马尔可夫链，其中在基于能量的模型中从$T(x^{'}|x)$采样是通过选择一个变量$x_i$，然后从$p_{model}$中该点关于在无向图中邻接点的条件分布中采样。只要一些变量在给定相邻变量时是条件独立的，那么这些变量就可以被同时采样。

6. 不同峰值之间的混合挑战

	使用$MCMC$方法的主要难点在于马尔可夫链的**混合**通常不理想。
