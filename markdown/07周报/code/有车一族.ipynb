{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aurai.data_source as ds\n",
    "# 根据dsId获取数据源信息\n",
    "dsId=\"5cb92eda46e0fb000e6f539f\"\n",
    "dsCycle=\"yyyyMMdd\"\n",
    "ds.describeDS(dsId)\n",
    "\n",
    "# 载入数据\n",
    "data = ds.load(dsId)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn. import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# input parameters:\n",
    "# tbName: 一个dataframe\n",
    "# catCols: 一个list，存储类别型变量\n",
    "# colDrop：一个list，存储型变量\n",
    "def dataTransform(tbName=None,catCols=None ,colDrop=None):\n",
    "    if isinstance(tbName,pd.DataFrame):\n",
    "        cols = tbName.columns\n",
    "        if isinstance(colDrop,list):\n",
    "            cols=list(set(cols).difference(set(colDrop)))\n",
    "            if isinstance(catCols,list):\n",
    "                catCols=list(set(catCols).difference(set(colDrop)))\n",
    "                conCols=list(set(cols).difference(set(catCols)))\n",
    "                \n",
    "                 # 针对连续型变量，将所有值转换成float型\n",
    "                for conCol in conCols:\n",
    "                    tbName[conCol]=tbName[conCol].map(lambda i: np.nan if(i=='\\\\N' or i=='NaN' or i=='nan' ) else i).astype(np.dtype('float64'))\n",
    "                data_con = tbName[conCols].fillna(0)\n",
    "                  # 针对类别型变量，做one-hot编码处理\n",
    "                for subCol in catCols:\n",
    "                    subDummies = pd.get_dummies(tbName[subCol], prefix=subCol)\n",
    "                    data_con = data_con.join(subDummies)\n",
    "                    \n",
    "                data_con_cat = data_con\n",
    "                \n",
    "                return data_con_cat\n",
    "        else:\n",
    "            raise ValueError('colDrop should be a list!')\n",
    "\n",
    "\n",
    "#data_x : Training data\n",
    "#degree : The degree of the polynomial features. integer\n",
    "def data_transform_polynomial(data_x,degree):\n",
    "    if degree==1:\n",
    "        X_redegree = data_x\n",
    "    else:\n",
    "        poly = preprocessing.PolynomialFeatures(degree)\n",
    "        X_redegree = poly.fit_transform(data_x)\n",
    "    return {'x' : X_redegree}\n",
    "\n",
    "\n",
    "#transform_type : datatransform such as 'Smote' 'Naive' 'Woe'\n",
    "#smote_ratio :  the keys correspond to the targeted classes. The values correspond to the desired number of samples.\n",
    "#data_x : Training data\n",
    "#data_y : Target values\n",
    "def data_transform_oversampling(transform_type,smote_ratio,data_x,data_y):\n",
    "    if transform_type=='Smote':\n",
    "        nv=sum(data_y==False)\n",
    "        pv = round(nv * smote_ratio)\n",
    "        ratio = {False : nv ,True : pv }\n",
    "        X_resampled, y_resampled = SMOTE(ratio = ratio).fit_sample(data_x, data_y)\n",
    "    elif transform_type=='Naive':\n",
    "        nv=sum(data_y==False)\n",
    "        pv = round(nv * smote_ratio)\n",
    "        ratio = {False : nv ,True : pv }\n",
    "        ros = RandomOverSampler(ratio = ratio,random_state=0)\n",
    "        X_resampled, y_resampled = ros.fit_sample(data_x, data_y)\n",
    "    else:\n",
    "        X_resampled, y_resampled = data_x, data_y\n",
    "    return {'x' : X_resampled, 'y' : y_resampled}\n",
    "\n",
    "\n",
    "# 切分训练集与测试集\n",
    "# input：\n",
    "def getTrainTestSample(df, taregt, test_size=0.5):\n",
    "    data_cols = list(df.columns)\n",
    "    train_data, test_data = train_test_split(df, test_size=test_size)\n",
    "\n",
    "    # 获取feature与target\n",
    "    target = taregt.upper()\n",
    "    data_cols.remove(target)\n",
    "    feature = data_cols\n",
    "\n",
    "    train_X = train_data[feature]\n",
    "    train_y = train_data[target]\n",
    "    test_X = test_data[feature]\n",
    "    test_y = test_data[target]\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "# get import feature\n",
    "# inputs:\n",
    "#        model 【】\n",
    "#                  model = RandomForestClassifier()\n",
    "#        train_feature 【a dataframe,which contains the feature to be trained】\n",
    "#        train_target 【a dataframe,which contains the target to be trained】\n",
    "#        fi_threshold 【a value from 0-100,to control the threshold to be used for training】\n",
    "# output: featureImporColumn 【importance column list according to the importance value】\n",
    "#         featureImporValue   【importance feature value according to the value】\n",
    "def getImpFeature(model, train_X, train_y, fi_threshold=10):\n",
    "    model.fit(train_X, train_y)\n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    important_idx = np.where(feature_importance > fi_threshold)[0]\n",
    "    sorted_idx = np.argsort(feature_importance[important_idx])[::-1]\n",
    "    impFeatureValues = feature_importance[important_idx[sorted_idx]]\n",
    "    impFeatureCols = train_X.iloc[:,important_idx[sorted_idx]].columns\n",
    "    return impFeatureCols,impFeatureValues\n",
    "\n",
    "def visualImporFeature():\n",
    "    pass\n",
    "\n",
    "def modelTrain(model,parameters,train_X,train_y,cv=5,scoring='f1'):\n",
    "    clf = GridSearchCV(estimator=model,param_grid=parameters,cv=cv,scoring=scoring)\n",
    "    clf.fit(X=train_X,y=train_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def plotROC(true_label,predict_prob,roc_auc):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_label, predict_prob)\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='RF(area = {0:0.2f})'\n",
    "         ''.format(roc_auc))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 对预测pro进行切断来看结果 \n",
    "def calBinPredProb(true_label,predict_prob):\n",
    "    temp=pd.DataFrame({'true_label':true_label,'predict_prob':predict_prob})\n",
    "    bins=np.arange(0,1.1,0.1)\n",
    "    temp['predict_prob_seg']=pd.cut(temp['predict_prob'],bins=bins)\n",
    "    return temp[['true_label','predict_prob_seg']].groupby('predict_prob_seg').aggregate(['count','sum'])\n",
    "\n",
    "    \n",
    "#true_label : the true label \n",
    "#predict_prob : thre predicted prob\n",
    "#thre: the threshold to seperate 0 and 1\n",
    "def model_evaluate(true_label,predict_prob,thre):\n",
    "    predict_label = np.where(predict_prob>thre,1,0)\n",
    "    confusion_matrix = metrics.confusion_matrix(true_label, predict_label)\n",
    "    \n",
    "    accuracy =metrics.accuracy_score(true_label, predict_label)    \n",
    "    precision = metrics.precision_score(true_label, predict_label)\n",
    "    recall = metrics.recall_score(true_label, predict_label)\n",
    "    f1 = metrics.f1_score(true_label, predict_label)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_label, predict_prob)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    prc = metrics.average_precision_score(true_label,predict_prob)\n",
    "    \n",
    "    \n",
    "    print('ROC图如下：')\n",
    "    plotROC(true_label,predict_prob,roc_auc)\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(\"------------------------- \")\n",
    "    print(\"| TP: %5d | FP: %5d |\" % (confusion_matrix[1, 1], confusion_matrix[0, 1]))\n",
    "    print(\"----------------------- \")\n",
    "    print(\"| FN: %5d | TN: %5d |\" % (confusion_matrix[1, 0], confusion_matrix[0, 0]))\n",
    "    print(\" ------------------------- \")\n",
    "    \n",
    "    #print('ROC图如下：')\n",
    "    #true_label_len= len(true_label)\n",
    "    #for i in range(0,true_label_len):\n",
    "    #    plot.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    print('预测结果分段统计，预测值与实际命中情况统计')\n",
    "    print(calBinPredProb(true_label,predict_prob))\n",
    "    \n",
    "    return {'accuracy':round(accuracy,4),'precision':round(precision,4),'recall':round(recall,4),'f1':round(f1,4),'roc_auc':roc_auc,'prc':prc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# 数据预处理\n",
    "########################################################################### \n",
    "tbName=data\n",
    "catCols =[\n",
    "'user_id' # 用户编号\n",
    ",'bill_no' # 手机号码\n",
    ",'city_id' # 城市\n",
    ",'sex_new' # 性别\n",
    ",'origin' # 籍贯\n",
    ",'real_name_flag_new' # 实名认证标识\n",
    ",'vpmn_flag' # 是否虚拟网成员\n",
    ",'gpr_memb_flag' # 是否集团网成员\n",
    ",'vip_flag' # 是否大客户\n",
    ",'upay_flag' # 统一支付用户标识\n",
    ",'famstru' # 家庭结构\n",
    ",'occu' # 职业\n",
    ",'sub_occu_name' # 细分的职业\n",
    ",'life_stage' # 人生阶段\n",
    ",'if_salariat' # 是否工薪阶层\n",
    ",'edu_level' # 教育水平\n",
    ",'stay_city_name_new' # 居住城市\n",
    ",'work_city_name_new' # 工作城市\n",
    ",'stay_town_flag' # 是否城镇居民\n",
    ",'fir_imei_brand' # 排名第一终端品牌\n",
    ",'new_imei_flag' # 新手机标识\n",
    ",'drv_flag' # 是否司机\n",
    "]\n",
    "colDrop =  [\n",
    "'user_id'\n",
    ",'bill_no'\n",
    ",'city_id'\n",
    ",'car_flag'\n",
    ",'train_test_flag'\n",
    ",'wz_sms_cnt' # 近一年违章短信接收次数\n",
    "]\n",
    "\n",
    "# 对数据进行处理，连续值中Nan转换为0，离散值转换为独热编码\n",
    "data_X = dataTransform(tbName=tbName,catCols=catCols ,colDrop=colDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_y=pd.concat([data_X,data[['car_flag','train_test_flag']]],axis=1)\n",
    "data_X_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "#切分训练集与测试集  \n",
    "###########################################################################\n",
    "cols = list(data_X_y.columns)\n",
    "cols.remove('car_flag')\n",
    "cols.remove('train_test_flag')\n",
    "data_train = data_X_y[data_X_y['train_test_flag']==1]\n",
    "data_test = data_X_y[data_X_y['train_test_flag']==0]\n",
    "#data_train_X, data_test_X, data_train_y, data_test_y = train_test_split(data_X,data[['car_flag']], test_size=0.5, random_state=0)\n",
    "\n",
    "data_train_X = data_train[cols]\n",
    "data_train_y = data_train['car_flag']\n",
    "data_test_X = data_test[cols]\n",
    "data_test_y = data_test['car_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# 获取显著性特征  \n",
    "########################################################################### \n",
    "# n_estimators 基评估器的数量\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "fi_threshold = 5\n",
    "impFeatureCols,impFeatureValues = getImpFeature(model=model, train_X=data_train_X, train_y=np.ravel(data_train_y.values), fi_threshold=fi_threshold)\n",
    "\n",
    "pd.DataFrame({'impFeatureCols':impFeatureCols,'impFeatureValues':impFeatureValues})\n",
    "pd.DataFrame({'impFeatureCols':impFeatureCols,'impFeatureValues':impFeatureValues}).to_csv(r'importFeatures.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impFeatureCols=pd.read_csv(r'importFeatures.csv')['impFeatureCols']\n",
    "impFeatureCols\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# 模型训练, 调参、评估 \n",
    "########################################################################### \n",
    "model = RandomForestClassifier(min_samples_leaf=50)\n",
    "parameters = {\n",
    "\t\t\t  'n_estimators':[100,200,300,400,500]\n",
    "\t\t\t }\n",
    "train_X = data_train[impFeatureCols]\n",
    "train_y = data_train['car_flag']\n",
    "cv = 5\n",
    "scoring='f1'\n",
    "clf = modelTrain(model,parameters,train_X,train_y,cv=5,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=data_train_X[impFeatureCols]\n",
    "train_y=data_train['car_flag']\n",
    "\n",
    "#model = RandomForestClassifier(min_samples_leaf=50,n_estimators=200)\n",
    "#clf = model.fit(train_X,train_y)\n",
    "joblib.dump(clf,'rf.pkl')\n",
    "clf=joblib.load('rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_predict_y = clf.predict_proba(X=train_X)[:,1]\n",
    "evalTrain = model_evaluate(true_label=train_y,predict_prob=data_train_predict_y,thre=0.5)\n",
    "evalTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = data_test_X[impFeatureCols]\n",
    "test_y = data_test['car_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=joblib.load('rf.pkl')\n",
    "test_X = data_test_X[impFeatureCols]\n",
    "test_y = data_test['car_flag']\n",
    "data_test_predict_y = clf.predict_proba(X=test_X)[:,1]\n",
    "\n",
    "#evalTest = model_evaluate(true_label=test_y,predict_prob=data_test_predict_y,thre=0.5)\n",
    "#evalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalTest = model_evaluate(true_label=test_y,predict_prob=data_test_predict_y,thre=0.5)\n",
    "evalTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('jupyter': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "141c5e0ba87e97013844de5b21d12d023199bf67a08052ba51b9f2de1a481a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
